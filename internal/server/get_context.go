package server

import (
	"context"
	"fmt"
	"sort"
	"strings"
	"unicode/utf8"

	"connectrpc.com/connect"
	"github.com/hsn0918/rag/internal/adapters"
	"github.com/hsn0918/rag/internal/clients/openai"
	ragv1 "github.com/hsn0918/rag/internal/gen/rag/v1"
	"github.com/hsn0918/rag/internal/logger"
	"go.uber.org/zap"
)

// GetContext å®ç°æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½
//
// å®Œæ•´çš„RAG(Retrieval-Augmented Generation)æµç¨‹:
// 1. ä½¿ç”¨å¤§æ¨¡å‹æå–ç”¨æˆ·æŸ¥è¯¢ä¸­çš„å…³é”®è¯
// 2. ç”ŸæˆæŸ¥è¯¢å‘é‡è¿›è¡Œè¯­ä¹‰æœç´¢
// 3. å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½é‡æ’åº
// 4. ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”
func (s *RagServer) GetContext(
	ctx context.Context,
	req *connect.Request[ragv1.GetContextRequest],
) (*connect.Response[ragv1.GetContextResponse], error) {
	query := req.Msg.GetQuery()

	if query == "" {
		return nil, connect.NewError(connect.CodeInvalidArgument, fmt.Errorf("query is required"))
	}

	logger.GetLogger().Info("å¼€å§‹å¤„ç†æ™ºèƒ½æ–‡æ¡£æ£€ç´¢è¯·æ±‚",
		zap.String("query", query),
		zap.Int("query_length", len(query)),
	)

	// ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ†è¯å’Œå…³é”®è¯æå–
	keywords, err := s.generateKeywords(ctx, query)
	if err != nil {
		logger.GetLogger().Error("å¤§æ¨¡å‹å…³é”®è¯æå–å¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to generate keywords: %w", err))
	}
	logger.GetLogger().Debug("å¤§æ¨¡å‹å…³é”®è¯æå–å®Œæˆ",
		zap.Strings("keywords", keywords),
	)

	// ç¬¬äºŒæ­¥ï¼šç”Ÿæˆè¯­ä¹‰å‘é‡è¿›è¡Œç›¸ä¼¼æ€§æœç´¢
	// ä¼˜å…ˆä½¿ç”¨æå–çš„å…³é”®è¯ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢
	queryText := strings.Join(keywords, " ")
	if queryText == "" {
		queryText = query
	}
	queryVector, err := s.generateEmbedding(ctx, queryText)
	if err != nil {
		logger.GetLogger().Error("æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to generate query embedding: %w", err))
	}

	// ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œå‘é‡ç›¸ä¼¼æ€§æœç´¢ï¼Œè·å–å€™é€‰æ–‡æ¡£å—
	similarChunks, err := s.searchSimilarChunks(ctx, queryVector, 15) // è·å–æ›´å¤šå€™é€‰ç”¨äºé‡æ’
	if err != nil {
		logger.GetLogger().Error("å‘é‡ç›¸ä¼¼æ€§æœç´¢å¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to search similar chunks: %w", err))
	}

	if len(similarChunks) == 0 {
		logger.GetLogger().Warn("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£", zap.String("query", query))
		return connect.NewResponse(&ragv1.GetContextResponse{
			Context: fmt.Sprintf("æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ '%s' ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚", query),
		}), nil
	}

	// ç¬¬å››æ­¥ï¼šæ™ºèƒ½é‡æ’åº - ç»¼åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…
	rankedChunks := s.rerankChunksWithKeywords(similarChunks, query, keywords)

	// ç¬¬äº”æ­¥ï¼šä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–æ€»ç»“å›ç­”
	contextContent, err := s.generateContextSummary(ctx, rankedChunks, query)
	if err != nil {
		logger.GetLogger().Error("å¤§æ¨¡å‹æ€»ç»“ç”Ÿæˆå¤±è´¥", zap.Error(err))
		// é™çº§åˆ°æ¨¡æ¿å›ç­”
		contextContent = s.buildContextResponse(rankedChunks, query)
	}

	logger.GetLogger().Info("æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å®Œæˆ",
		zap.String("query", query),
		zap.Int("chunks_found", len(similarChunks)),
		zap.Int("chunks_used", len(rankedChunks)),
		zap.Int("response_length", len(contextContent)),
	)

	return connect.NewResponse(&ragv1.GetContextResponse{
		Context: contextContent,
	}), nil
}

// searchSimilarChunks ä½¿ç”¨pgvectoræ‰§è¡Œè¯­ä¹‰å‘é‡æœç´¢
//
// åŸºäºæŸ¥è¯¢å‘é‡åœ¨PostgreSQLæ•°æ®åº“ä¸­æœç´¢ç›¸ä¼¼çš„æ–‡æ¡£å—ï¼Œ
// ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç®—æ³•è®¡ç®—ç›¸å…³æ€§ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
func (s *RagServer) searchSimilarChunks(ctx context.Context, queryVector []float32, limit int) ([]adapters.ChunkSearchResult, error) {
	// ä½¿ç”¨æ•°æ®åº“çš„å‘é‡æœç´¢åŠŸèƒ½
	results, err := s.DB.SearchSimilarChunks(ctx, queryVector, limit, 0.3) // 0.3æ˜¯ç›¸ä¼¼åº¦é˜ˆå€¼
	if err != nil {
		return nil, fmt.Errorf("database search failed: %w", err)
	}

	logger.GetLogger().Debug("Vector search completed",
		zap.Int("results_count", len(results)),
		zap.Int("query_vector_dim", len(queryVector)),
	)

	return results, nil
}

// rerankChunks å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ’åºå’Œè¿‡æ»¤
func (s *RagServer) rerankChunks(chunks []adapters.ChunkSearchResult, query string) []adapters.ChunkSearchResult {
	// åŸºäºå¤šä¸ªå› ç´ è¿›è¡Œé‡æ’åº
	sort.Slice(chunks, func(i, j int) bool {
		// ç»¼åˆè¯„åˆ†ï¼šç›¸ä¼¼åº¦ + å†…å®¹é•¿åº¦ + å…³é”®è¯åŒ¹é…
		scoreI := s.calculateChunkScore(chunks[i], query)
		scoreJ := s.calculateChunkScore(chunks[j], query)
		return scoreI > scoreJ
	})

	// è¿‡æ»¤ä½è´¨é‡ç»“æœï¼Œæœ€å¤šè¿”å›5ä¸ªæœ€ç›¸å…³çš„å—
	maxChunks := 5
	if len(chunks) > maxChunks {
		chunks = chunks[:maxChunks]
	}

	// è¿›ä¸€æ­¥è¿‡æ»¤ï¼šç§»é™¤ç›¸ä¼¼åº¦è¿‡ä½çš„ç»“æœ
	var filteredChunks []adapters.ChunkSearchResult
	for _, chunk := range chunks {
		if chunk.
			Similarity > 0.4 { // ç›¸ä¼¼åº¦é˜ˆå€¼
			filteredChunks = append(filteredChunks, chunk)
		}
	}

	logger.GetLogger().Debug("Chunks reranked and filtered",
		zap.Int("original_count", len(chunks)),
		zap.Int("filtered_count", len(filteredChunks)),
	)

	return filteredChunks
}

// calculateChunkScore è®¡ç®—åˆ†å—çš„ç»¼åˆè¯„åˆ†
func (s *RagServer) calculateChunkScore(chunk adapters.ChunkSearchResult, query string) float64 {
	// åŸºç¡€ç›¸ä¼¼åº¦æƒé‡
	score := float64(chunk.Similarity) * 0.7

	// å†…å®¹é•¿åº¦åŠ åˆ†ï¼ˆé€‚ä¸­é•¿åº¦æ›´å¥½ï¼‰
	contentLength := len(chunk.Content)
	if contentLength > 100 && contentLength < 1000 {
		score += 0.1
	}

	// å…³é”®è¯åŒ¹é…åŠ åˆ†
	queryLower := strings.ToLower(query)
	contentLower := strings.ToLower(chunk.Content)

	// ç®€å•çš„å…³é”®è¯åŒ¹é…è¯„åˆ†
	queryWords := strings.Fields(queryLower)
	matchCount := 0
	for _, word := range queryWords {
		if strings.Contains(contentLower, word) {
			matchCount++
		}
	}

	if len(queryWords) > 0 {
		keywordScore := float64(matchCount) / float64(len(queryWords))
		score += keywordScore * 0.2
	}

	return score
}

// buildContextResponse æ„å»ºç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡å“åº”
func (s *RagServer) buildContextResponse(chunks []adapters.ChunkSearchResult, query string) string {
	if len(chunks) == 0 {
		return fmt.Sprintf("æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ '%s' ç›¸å…³çš„å†…å®¹ã€‚", query)
	}

	var contextBuilder strings.Builder

	// æ·»åŠ æŸ¥è¯¢æ€»ç»“
	contextBuilder.WriteString(fmt.Sprintf("åŸºäºæŸ¥è¯¢ã€Œ%sã€æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³å†…å®¹ï¼š\n\n", query))

	// æ·»åŠ ç›¸å…³å†…å®¹å—
	for i, chunk := range chunks {
		contextBuilder.WriteString(fmt.Sprintf("## ç›¸å…³å†…å®¹ %d (ç›¸ä¼¼åº¦: %.2f)\n", i+1, chunk.Similarity))

		// æ¸…ç†å’Œæ ¼å¼åŒ–å†…å®¹
		cleanContent := s.cleanAndFormatChunkContent(chunk.Content)
		contextBuilder.WriteString(cleanContent)
		contextBuilder.WriteString("\n\n")

		// æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
		if chunk.Metadata != nil {
			if chunkType, ok := chunk.Metadata["chunk_type"].(string); ok && chunkType != "" {
				contextBuilder.WriteString(fmt.Sprintf("*[å†…å®¹ç±»å‹: %s]*\n\n", chunkType))
			}
		}
	}

	// æ·»åŠ ä½¿ç”¨è¯´æ˜
	contextBuilder.WriteString("---\n")
	contextBuilder.WriteString("ğŸ’¡ æç¤ºï¼šä»¥ä¸Šå†…å®¹æŒ‰ç›¸å…³æ€§æ’åºï¼Œæ‚¨å¯ä»¥åŸºäºè¿™äº›ä¿¡æ¯è¿›è¡Œè¿›ä¸€æ­¥çš„è¯¢é—®ã€‚")

	return contextBuilder.String()
}

// cleanAndFormatChunkContent æ¸…ç†å’Œæ ¼å¼åŒ–åˆ†å—å†…å®¹
func (s *RagServer) cleanAndFormatChunkContent(content string) string {
	// åŸºæœ¬æ¸…ç†
	content = strings.TrimSpace(content)

	// ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦
	lines := strings.Split(content, "\n")
	var cleanedLines []string

	lastWasEmpty := false
	for _, line := range lines {
		trimmedLine := strings.TrimSpace(line)

		if trimmedLine == "" {
			if !lastWasEmpty {
				cleanedLines = append(cleanedLines, "")
			}
			lastWasEmpty = true
		} else {
			cleanedLines = append(cleanedLines, trimmedLine)
			lastWasEmpty = false
		}
	}

	// ç¡®ä¿å†…å®¹ä¸ä¼šå¤ªé•¿
	result := strings.Join(cleanedLines, "\n")
	if len(result) > 2000 {
		result = s.safeUTF8Truncate(result, 1000) + "..."
	}

	// ç¡®ä¿ç»“æœæ˜¯æœ‰æ•ˆçš„UTF-8
	result = s.sanitizeUTF8(result)

	return result
}

// generateKeywords ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½æå–æŸ¥è¯¢å…³é”®è¯
//
// è°ƒç”¨é…ç½®çš„LLMæœåŠ¡(å¦‚DeepSeek)è¿›è¡Œä¸­æ–‡åˆ†è¯å’Œå…³é”®è¯æå–ï¼Œ
// è‡ªåŠ¨è¿‡æ»¤åœç”¨è¯ï¼Œä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œå®ä½“åè¯ï¼Œ
// å¦‚æœLLMè°ƒç”¨å¤±è´¥ä¼šé™çº§åˆ°æœ¬åœ°ç®€å•åˆ†è¯
func (s *RagServer) generateKeywords(ctx context.Context, query string) ([]string, error) {
	messages := []openai.Message{
		{
			Role: "system",
			Content: `ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡å…³é”®è¯æå–ä¸“å®¶ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ä¸­æå–æœ€é‡è¦çš„å…³é”®è¯ã€‚

è¦æ±‚ï¼š
1. æå–3-8ä¸ªæœ€ç›¸å…³çš„å…³é”®è¯
2. å¿½ç•¥åœè¯ï¼ˆå¦‚ï¼šçš„ã€äº†ã€åœ¨ã€æ˜¯ã€æˆ‘ã€æœ‰ã€å’Œç­‰ï¼‰
3. ä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œå®ä½“åè¯
4. æ¯è¡Œä¸€ä¸ªå…³é”®è¯ï¼Œä¸è¦ç¼–å·
5. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–å†…å®¹

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"è¯·å¸®æˆ‘æ‰¾ä¸€ä¸‹å…³äºæœºå™¨å­¦ä¹ ç®—æ³•çš„èµ„æ–™"
è¾“å‡ºï¼š
æœºå™¨å­¦ä¹ 
ç®—æ³•
èµ„æ–™`,
		},
		{
			Role:    "user",
			Content: query,
		},
	}

	resp, err := s.LLM.CreateChatCompletionWithDefaults(s.Config.Services.LLM.Model, messages)
	if err != nil {
		logger.GetLogger().Error("LLMå…³é”®è¯æå–å¤±è´¥", zap.Error(err))
		// é™çº§ä¸ºç®€å•åˆ†è¯
		return s.fallbackKeywords(query), nil
	}

	if len(resp.Choices) == 0 {
		return s.fallbackKeywords(query), nil
	}

	// è§£æLLMè¿”å›çš„å…³é”®è¯
	content := resp.Choices[0].Message.Content
	lines := strings.Split(strings.TrimSpace(content), "\n")
	var keywords []string

	for _, line := range lines {
		keyword := strings.TrimSpace(line)
		if keyword != "" && len(keyword) > 1 {
			keywords = append(keywords, keyword)
		}
	}

	if len(keywords) == 0 {
		return s.fallbackKeywords(query), nil
	}

	return keywords, nil
}

// fallbackKeywords æœ¬åœ°é™çº§åˆ†è¯å®ç°
//
// å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼Œä½¿ç”¨åŸºäºå­—ç¬¦è§„åˆ™çš„ç®€å•ä¸­æ–‡åˆ†è¯ï¼Œ
// åŒ…å«åŸºç¡€åœç”¨è¯è¿‡æ»¤ï¼Œç¡®ä¿æœåŠ¡çš„å¯ç”¨æ€§
func (s *RagServer) fallbackKeywords(query string) []string {
	// ç®€å•çš„ä¸­æ–‡åˆ†è¯ä½œä¸ºé™çº§æ–¹æ¡ˆ
	stopWords := map[string]bool{
		"çš„": true, "äº†": true, "åœ¨": true, "æ˜¯": true, "æˆ‘": true, "æœ‰": true, "å’Œ": true,
		"å°±": true, "ä¸": true, "äºº": true, "éƒ½": true, "ä¸€": true, "ä¸€ä¸ª": true, "ä¸Š": true,
		"ä¹Ÿ": true, "å¾ˆ": true, "åˆ°": true, "è¯´": true, "è¦": true, "å»": true, "ä½ ": true,
		"ä¼š": true, "ç€": true, "æ²¡æœ‰": true, "çœ‹": true, "å¥½": true, "è‡ªå·±": true, "è¿™": true,
	}

	var keywords []string
	runes := []rune(query)
	var currentWord []rune

	for _, r := range runes {
		if (r >= 0x4e00 && r <= 0x9fff) || (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z') || (r >= '0' && r <= '9') {
			currentWord = append(currentWord, r)
		} else {
			if len(currentWord) > 0 {
				word := string(currentWord)
				if len(word) > 1 && !stopWords[word] {
					keywords = append(keywords, word)
				}
				currentWord = nil
			}
		}
	}

	if len(currentWord) > 0 {
		word := string(currentWord)
		if len(word) > 1 && !stopWords[word] {
			keywords = append(keywords, word)
		}
	}

	return keywords
}

// rerankChunksWithKeywords æ··åˆç®—æ³•æ™ºèƒ½é‡æ’åº
//
// ç»¼åˆå‘é‡ç›¸ä¼¼åº¦(40%)ã€å…³é”®è¯åŒ¹é…(30%)ã€çŸ­è¯­åŒ¹é…(20%)å’Œå†…å®¹è´¨é‡(10%)
// å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åºï¼Œæå‡ç›¸å…³æ€§å’Œå‡†ç¡®æ€§
func (s *RagServer) rerankChunksWithKeywords(chunks []adapters.ChunkSearchResult, query string, keywords []string) []adapters.ChunkSearchResult {
	// ä¸ºæ¯ä¸ªchunkè®¡ç®—ç»¼åˆè¯„åˆ†
	for i := range chunks {
		score := s.calculateAdvancedChunkScore(chunks[i], query, keywords)
		// å°†scoreå­˜å‚¨åœ¨metadataä¸­ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
		if chunks[i].Metadata == nil {
			chunks[i].Metadata = make(map[string]interface{})
		}
		chunks[i].Metadata["advanced_score"] = score
	}

	// æŒ‰ç»¼åˆè¯„åˆ†é‡æ’åº
	sort.Slice(chunks, func(i, j int) bool {
		scoreI, _ := chunks[i].Metadata["advanced_score"].(float64)
		scoreJ, _ := chunks[j].Metadata["advanced_score"].(float64)
		return scoreI > scoreJ
	})

	// è¿‡æ»¤ä½è´¨é‡ç»“æœ
	maxChunks := 5
	if len(chunks) > maxChunks {
		chunks = chunks[:maxChunks]
	}

	var filteredChunks []adapters.ChunkSearchResult
	for _, chunk := range chunks {
		if chunk.Similarity > 0.25 { // é™ä½é˜ˆå€¼ä»¥è·å¾—æ›´å¤šå€™é€‰
			filteredChunks = append(filteredChunks, chunk)
		}
	}

	logger.GetLogger().Debug("Advanced reranking completed",
		zap.Int("original_count", len(chunks)),
		zap.Int("filtered_count", len(filteredChunks)),
		zap.Strings("keywords", keywords),
	)

	return filteredChunks
}

// calculateAdvancedChunkScore å¤šç»´åº¦è¯„åˆ†ç®—æ³•
//
// æƒé‡åˆ†é…: å‘é‡ç›¸ä¼¼åº¦40% + å…³é”®è¯åŒ¹é…30% + çŸ­è¯­åŒ¹é…20% + å†…å®¹è´¨é‡10%
// ç¡®ä¿æ—¢è€ƒè™‘è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œåˆå…¼é¡¾ç²¾ç¡®åŒ¹é…å’Œå†…å®¹å¯è¯»æ€§
func (s *RagServer) calculateAdvancedChunkScore(chunk adapters.ChunkSearchResult, query string, keywords []string) float64 {
	// åŸºç¡€å‘é‡ç›¸ä¼¼åº¦ (40%)
	score := float64(chunk.Similarity) * 0.4

	contentLower := strings.ToLower(chunk.Content)

	// ç²¾ç¡®å…³é”®è¯åŒ¹é… (30%)
	keywordScore := 0.0
	if len(keywords) > 0 {
		matchCount := 0
		for _, keyword := range keywords {
			if strings.Contains(contentLower, strings.ToLower(keyword)) {
				matchCount++
			}
		}
		keywordScore = float64(matchCount) / float64(len(keywords))
	}
	score += keywordScore * 0.3

	// çŸ­è¯­åŒ¹é… (20%)
	queryLower := strings.ToLower(query)
	if strings.Contains(contentLower, queryLower) {
		score += 0.2 // å®Œæ•´æŸ¥è¯¢çŸ­è¯­åŒ¹é…å¥–åŠ±
	}

	// å†…å®¹è´¨é‡è¯„åˆ† (10%)
	contentLength := len(chunk.Content)
	if contentLength > 100 && contentLength < 1500 {
		score += 0.1
	} else if contentLength > 50 {
		score += 0.05
	}

	return score
}

// generateContextSummary ä½¿ç”¨LLMæ™ºèƒ½ç”Ÿæˆä¸Šä¸‹æ–‡æ€»ç»“
//
// åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µï¼Œä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æå’Œæ™ºèƒ½æ€»ç»“ï¼Œ
// ç”Ÿæˆé’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„é«˜è´¨é‡ã€ç»“æ„åŒ–å›ç­”
func (s *RagServer) generateContextSummary(ctx context.Context, chunks []adapters.ChunkSearchResult, query string) (string, error) {
	if len(chunks) == 0 {
		return "", fmt.Errorf("no chunks to summarize")
	}

	// é¦–å…ˆæ„å»ºåŸå§‹ä¸Šä¸‹æ–‡ä¿¡æ¯ä¾›LLMåˆ†æ
	rawContextBuilder := strings.Builder{}
	rawContextBuilder.WriteString("ä»¥ä¸‹æ˜¯ä»çŸ¥è¯†åº“æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š\n\n")

	for i, chunk := range chunks {
		cleanContent := s.cleanAndFormatChunkContent(chunk.Content)
		rawContextBuilder.WriteString(fmt.Sprintf("**ä¿¡æ¯ç‰‡æ®µ%d (ç›¸ä¼¼åº¦: %.3f):**\n", i+1, chunk.Similarity))
		rawContextBuilder.WriteString(cleanContent)

		// æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
		if chunk.Metadata != nil {
			if chunkType, ok := chunk.Metadata["chunk_type"].(string); ok && chunkType != "" {
				rawContextBuilder.WriteString(fmt.Sprintf("\n*[ç±»å‹: %s]*", chunkType))
			}
		}
		rawContextBuilder.WriteString("\n\n")
	}

	// æ„å»ºLLMæ€»ç»“æç¤ºè¯
	messages := []openai.Message{
		{
			Role: "system",
			Content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯åˆ†æå¸ˆï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·æŸ¥è¯¢å¯¹å¤šä¸ªä¿¡æ¯æºè¿›è¡Œæ™ºèƒ½æ€»ç»“å’Œåˆ†æã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†é˜…è¯»ç”¨æˆ·çš„æŸ¥è¯¢å’Œæ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
2. åˆ†æä¿¡æ¯ä¹‹é—´çš„å…³è”æ€§å’Œäº’è¡¥æ€§
3. ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–ã€å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”
4. å¦‚æœä¿¡æ¯ä¸è¶³ä»¥å®Œå…¨å›ç­”æŸ¥è¯¢ï¼Œè¯·è¯šå®è¯´æ˜
5. é€‚å½“å¼•ç”¨å…·ä½“çš„ä¿¡æ¯æ¥æºä»¥å¢åŠ å¯ä¿¡åº¦

å›ç­”æ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼
- é‡ç‚¹ä¿¡æ¯ç”¨**ç²—ä½“**çªå‡º
- åˆ†ç‚¹è¯´æ˜æ—¶ä½¿ç”¨æœ‰åºæˆ–æ— åºåˆ—è¡¨
- ä¿æŒé€»è¾‘æ¸…æ™°ã€è¯­è¨€ç®€æ´
- é•¿åº¦æ§åˆ¶åœ¨800å­—ä»¥å†…`,
		},
		{
			Role: "user",
			Content: fmt.Sprintf(`ç”¨æˆ·æŸ¥è¯¢ï¼š%s

ç›¸å…³ä¿¡æ¯ï¼š
%s

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæ£€ç´¢åˆ°çš„ä¿¡æ¯ä¸è¶³ä»¥å®Œå…¨å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºä¿¡æ¯ä¸è¶³çš„åœ°æ–¹ï¼Œå¹¶å»ºè®®ç”¨æˆ·å¦‚ä½•è·å¾—æ›´å®Œæ•´çš„ç­”æ¡ˆã€‚`, query, rawContextBuilder.String()),
		},
	}

	// è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“
	resp, err := s.LLM.CreateChatCompletionWithDefaults(s.Config.Services.LLM.Model, messages)
	if err != nil {
		logger.GetLogger().Error("LLMæ™ºèƒ½æ€»ç»“å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æ¨¡æ¿", zap.Error(err))
		// é™çº§åˆ°åŸºç¡€æ¨¡æ¿æ–¹æ¡ˆ
		return s.generateBasicContextSummary(chunks, query), nil
	}

	if len(resp.Choices) == 0 || resp.Choices[0].Message.Content == "" {
		logger.GetLogger().Warn("LLMè¿”å›ç©ºå†…å®¹ï¼Œå›é€€åˆ°åŸºç¡€æ¨¡æ¿")
		return s.generateBasicContextSummary(chunks, query), nil
	}

	intelligentSummary := resp.Choices[0].Message.Content

	// æ·»åŠ ç³»ç»Ÿæ ‡è¯†å’Œä½¿ç”¨è¯´æ˜
	var finalSummary strings.Builder
	finalSummary.WriteString(intelligentSummary)
	finalSummary.WriteString("\n\n---\n\n")
	finalSummary.WriteString("ğŸ’¡ **æç¤º**: ä»¥ä¸Šå›ç­”åŸºäºçŸ¥è¯†åº“æ£€ç´¢ç»“æœç”Ÿæˆï¼Œå¦‚éœ€äº†è§£æ›´è¯¦ç»†ä¿¡æ¯ï¼Œå¯ä»¥å°è¯•è°ƒæ•´æŸ¥è¯¢å…³é”®è¯æˆ–æå‡ºæ›´å…·ä½“çš„é—®é¢˜ã€‚")

	logger.GetLogger().Info("LLMæ™ºèƒ½æ€»ç»“ç”ŸæˆæˆåŠŸ",
		zap.String("query", query),
		zap.Int("chunks_count", len(chunks)),
		zap.Int("summary_length", len(intelligentSummary)),
	)

	return finalSummary.String(), nil
}

// generateBasicContextSummary åŸºç¡€æ¨¡æ¿æ€»ç»“ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
//
// å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆï¼Œæä¾›åŸºç¡€çš„ä¿¡æ¯æ•´ç†å’Œæ ¼å¼åŒ–
func (s *RagServer) generateBasicContextSummary(chunks []adapters.ChunkSearchResult, query string) string {
	var contextBuilder strings.Builder

	contextBuilder.WriteString(fmt.Sprintf("## å…³äºã€Œ%sã€çš„ç›¸å…³ä¿¡æ¯\n\n", query))

	// æ™ºèƒ½åˆ†ææŸ¥è¯¢ç±»å‹ï¼Œæä¾›é’ˆå¯¹æ€§çš„å¼•å¯¼
	queryType := s.analyzeQueryType(query)
	contextBuilder.WriteString(s.generateQueryTypeGuidance(queryType))

	// æ·»åŠ æ£€ç´¢åˆ°çš„ä¿¡æ¯
	contextBuilder.WriteString("### ğŸ“š æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹\n\n")

	for i, chunk := range chunks {
		cleanContent := s.cleanAndFormatChunkContent(chunk.Content)

		contextBuilder.WriteString(fmt.Sprintf("**%d. ç›¸å…³ä¿¡æ¯** (ç›¸ä¼¼åº¦: %.2f)\n\n", i+1, chunk.Similarity))
		contextBuilder.WriteString(cleanContent)
		contextBuilder.WriteString("\n\n")

		// æ·»åŠ ç®€å•çš„å…ƒæ•°æ®
		if chunk.Metadata != nil {
			if chunkType, ok := chunk.Metadata["chunk_type"].(string); ok && chunkType != "" {
				contextBuilder.WriteString(fmt.Sprintf("*ä¿¡æ¯ç±»å‹: %s*\n\n", chunkType))
			}
		}
	}

	// æ·»åŠ æ™ºèƒ½æ€»ç»“
	contextBuilder.WriteString("### ğŸ’¡ ä¿¡æ¯æ€»ç»“\n\n")
	contextBuilder.WriteString("åŸºäºä»¥ä¸Šæ£€ç´¢ç»“æœï¼Œè¿™äº›ä¿¡æ¯æ¶µç›–äº†æ‚¨æŸ¥è¯¢çš„ç›¸å…³æ–¹é¢ã€‚")
	contextBuilder.WriteString(s.generateQuerySpecificSummary(query, chunks))
	contextBuilder.WriteString("\n\n")

	contextBuilder.WriteString("å¦‚éœ€äº†è§£æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå»ºè®®æ‚¨ï¼š\n")
	contextBuilder.WriteString("- æŸ¥çœ‹ä¸Šè¿°å…·ä½“çš„ä¿¡æ¯ç‰‡æ®µ\n")
	contextBuilder.WriteString("- å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯é‡æ–°æŸ¥è¯¢\n")
	contextBuilder.WriteString("- æå‡ºæ›´è¯¦ç»†çš„é—®é¢˜ä»¥è·å¾—ç²¾å‡†ç­”æ¡ˆ\n")

	return contextBuilder.String()
}

// analyzeQueryType åˆ†ææŸ¥è¯¢ç±»å‹
func (s *RagServer) analyzeQueryType(query string) string {
	queryLower := strings.ToLower(query)

	// å®šä¹‰æŸ¥è¯¢ç±»å‹çš„å…³é”®è¯æ¨¡å¼
	patterns := map[string][]string{
		"how_to":     {"æ€ä¹ˆ", "å¦‚ä½•", "æ€æ ·", "æ€ä¹ˆåŠ", "how to", "how do"},
		"what_is":    {"ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ", "what is", "define", "å®šä¹‰"},
		"why":        {"ä¸ºä»€ä¹ˆ", "ä¸ºå•¥", "åŸå› ", "why", "because"},
		"comparison": {"æ¯”è¾ƒ", "å¯¹æ¯”", "åŒºåˆ«", "å·®å¼‚", "vs", "versus", "compare"},
		"list":       {"æœ‰å“ªäº›", "åŒ…æ‹¬", "ç§ç±»", "ç±»å‹", "list", "types"},
		"experience": {"ç»éªŒ", "å¿ƒå¾—", "ä½“ä¼š", "æ„Ÿå—", "experience"},
		"technical":  {"æŠ€æœ¯", "ç®—æ³•", "æ¶æ„", "å®ç°", "æŠ€æœ¯æ ˆ", "technical"},
		"project":    {"é¡¹ç›®", "å·¥ç¨‹", "ç³»ç»Ÿ", "åº”ç”¨", "project"},
	}

	for queryType, keywords := range patterns {
		for _, keyword := range keywords {
			if strings.Contains(queryLower, keyword) {
				return queryType
			}
		}
	}

	return "general"
}

// generateQueryTypeGuidance æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆå¼•å¯¼ä¿¡æ¯
func (s *RagServer) generateQueryTypeGuidance(queryType string) string {
	guidanceMap := map[string]string{
		"how_to":     "ä»¥ä¸‹ä¿¡æ¯å°†å¸®åŠ©æ‚¨äº†è§£å…·ä½“çš„æ“ä½œæ–¹æ³•å’Œæ­¥éª¤ï¼š\n\n",
		"what_is":    "ä»¥ä¸‹ä¿¡æ¯å°†å¸®åŠ©æ‚¨ç†è§£ç›¸å…³æ¦‚å¿µå’Œå®šä¹‰ï¼š\n\n",
		"why":        "ä»¥ä¸‹ä¿¡æ¯å°†å¸®åŠ©æ‚¨äº†è§£ç›¸å…³çš„åŸå› å’ŒèƒŒæ™¯ï¼š\n\n",
		"comparison": "ä»¥ä¸‹ä¿¡æ¯å°†å¸®åŠ©æ‚¨è¿›è¡Œæ¯”è¾ƒå’Œåˆ†æï¼š\n\n",
		"list":       "ä»¥ä¸‹ä¿¡æ¯åˆ—å‡ºäº†ç›¸å…³çš„é¡¹ç›®å’Œåˆ†ç±»ï¼š\n\n",
		"experience": "ä»¥ä¸‹æ˜¯ç›¸å…³çš„ç»éªŒåˆ†äº«å’Œå®è·µå¿ƒå¾—ï¼š\n\n",
		"technical":  "ä»¥ä¸‹æ˜¯ç›¸å…³çš„æŠ€æœ¯ä¿¡æ¯å’Œå®ç°ç»†èŠ‚ï¼š\n\n",
		"project":    "ä»¥ä¸‹æ˜¯ç›¸å…³çš„é¡¹ç›®ä¿¡æ¯å’Œå®è·µæ¡ˆä¾‹ï¼š\n\n",
		"general":    "ä»¥ä¸‹æ˜¯ä¸æ‚¨æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ï¼š\n\n",
	}

	return guidanceMap[queryType]
}

// generateQuerySpecificSummary ç”Ÿæˆé’ˆå¯¹ç‰¹å®šæŸ¥è¯¢çš„æ€»ç»“
func (s *RagServer) generateQuerySpecificSummary(query string, chunks []adapters.ChunkSearchResult) string {
	queryType := s.analyzeQueryType(query)

	summaryMap := map[string]string{
		"how_to":     "ä»æ“ä½œæ–¹æ³•çš„è§’åº¦æ¥çœ‹ï¼Œæ–‡æ¡£ä¸­æåˆ°çš„æ­¥éª¤å’Œå»ºè®®å¯ä»¥ä¸ºæ‚¨æä¾›å®ç”¨çš„æŒ‡å¯¼ã€‚",
		"what_is":    "ä»æ¦‚å¿µå®šä¹‰çš„è§’åº¦åˆ†æï¼Œç›¸å…³çš„è§£é‡Šå’Œè¯´æ˜åœ¨æ–‡æ¡£ä¸­æœ‰è¯¦ç»†æè¿°ã€‚",
		"why":        "ä»åŸå› åˆ†æçš„è§’åº¦æ¥çœ‹ï¼Œæ–‡æ¡£ä¸­æä¾›äº†ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯å’Œè§£é‡Šã€‚",
		"comparison": "ä»æ¯”è¾ƒåˆ†æçš„è§’åº¦æ¥çœ‹ï¼Œä¸åŒæ–¹æ¡ˆçš„ç‰¹ç‚¹å’Œå·®å¼‚åœ¨æ–‡æ¡£ä¸­æœ‰æ‰€ä½“ç°ã€‚",
		"list":       "ä»åˆ†ç±»æ•´ç†çš„è§’åº¦æ¥çœ‹ï¼Œç›¸å…³é¡¹ç›®çš„åˆ—ä¸¾å’Œè¯´æ˜åœ¨æ–‡æ¡£ä¸­æ¯”è¾ƒå…¨é¢ã€‚",
		"experience": "ä»å®è·µç»éªŒçš„è§’åº¦æ¥çœ‹ï¼Œæ–‡æ¡£ä¸­åˆ†äº«çš„ç»éªŒå’Œå¿ƒå¾—å…·æœ‰å‚è€ƒä»·å€¼ã€‚",
		"technical":  "ä»æŠ€æœ¯è§’åº¦åˆ†æï¼Œç›¸å…³çš„æŠ€æœ¯æ ˆã€æ¶æ„å’Œå®ç°æ–¹æ¡ˆåœ¨æ–‡æ¡£ä¸­æœ‰è¯¦ç»†è¯´æ˜ã€‚",
		"project":    "ä»é¡¹ç›®å®æ–½çš„è§’åº¦æ¥çœ‹ï¼Œç›¸å…³çš„é¡¹ç›®ç»éªŒå’Œå®è·µæ¡ˆä¾‹ä¸ºæ‚¨æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚",
		"general":    "è¿™äº›ä¿¡æ¯ä»å¤šä¸ªè§’åº¦ä¸ºæ‚¨çš„æŸ¥è¯¢æä¾›äº†ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†ã€‚",
	}

	return summaryMap[queryType]
}

// generateSmartResponse æ¨¡æ¿åŒ–é™çº§å›ç­”ç”Ÿæˆ
//
// å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆï¼ŒåŸºäºé¢„è®¾æ¨¡æ¿å’Œè§„åˆ™
// ç”Ÿæˆç»“æ„åŒ–å›ç­”ï¼Œç¡®ä¿ç”¨æˆ·å§‹ç»ˆèƒ½è·å¾—æœ‰ç”¨çš„å“åº”
func (s *RagServer) generateSmartResponse(query string, chunks []adapters.ChunkSearchResult) string {
	var responseBuilder strings.Builder

	// æ·»åŠ é—®é¢˜ç†è§£
	responseBuilder.WriteString(fmt.Sprintf("å…³äºã€Œ%sã€ï¼Œæˆ‘åœ¨ç›¸å…³æ–‡æ¡£ä¸­æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š\n\n", query))

	// åˆ†æå’Œæ€»ç»“å†…å®¹
	for i, chunk := range chunks {
		content := s.cleanAndFormatChunkContent(chunk.Content)
		responseBuilder.WriteString(fmt.Sprintf("**%d. ç›¸å…³ä¿¡æ¯ (ç›¸ä¼¼åº¦: %.2f)**\n", i+1, chunk.Similarity))
		responseBuilder.WriteString(content)
		responseBuilder.WriteString("\n\n")
	}

	// æ·»åŠ æ™ºèƒ½æ€»ç»“
	responseBuilder.WriteString("**æ€»ç»“ï¼š**\n")
	responseBuilder.WriteString("åŸºäºä»¥ä¸Šæ–‡æ¡£å†…å®¹ï¼Œè¿™äº›ä¿¡æ¯æ¶µç›–äº†æ‚¨è¯¢é—®çš„ä¸»è¦æ–¹é¢ã€‚")

	// æ ¹æ®æŸ¥è¯¢ç±»å‹æ·»åŠ ä¸åŒçš„å»ºè®®
	queryLower := strings.ToLower(query)
	if strings.Contains(queryLower, "ç»éªŒ") || strings.Contains(queryLower, "å·¥ä½œ") {
		responseBuilder.WriteString("ä»å·¥ä½œç»éªŒçš„è§’åº¦æ¥çœ‹ï¼Œæ–‡æ¡£ä¸­æåˆ°çš„ç›¸å…³èƒŒæ™¯å’Œå®è·µç»éªŒå¯ä»¥ä¸ºæ‚¨æä¾›å‚è€ƒã€‚")
	} else if strings.Contains(queryLower, "æŠ€æœ¯") || strings.Contains(queryLower, "å¼€å‘") {
		responseBuilder.WriteString("ä»æŠ€æœ¯è§’åº¦åˆ†æï¼Œç›¸å…³çš„æŠ€æœ¯æ ˆå’Œå¼€å‘ç»éªŒåœ¨æ–‡æ¡£ä¸­æœ‰è¯¦ç»†æè¿°ã€‚")
	} else if strings.Contains(queryLower, "é¡¹ç›®") {
		responseBuilder.WriteString("é¡¹ç›®ç›¸å…³çš„ä¿¡æ¯æ˜¾ç¤ºäº†å…·ä½“çš„å®æ–½ç»éªŒå’Œæˆæœã€‚")
	}

	responseBuilder.WriteString("\n\nğŸ’¡ å¦‚éœ€äº†è§£æ›´å…·ä½“çš„ä¿¡æ¯ï¼Œå»ºè®®æ‚¨æŸ¥çœ‹ä¸Šè¿°ç›¸å…³å†…å®¹æˆ–æå‡ºæ›´è¯¦ç»†çš„é—®é¢˜ã€‚")

	return responseBuilder.String()
}

// safeUTF8Truncate å®‰å…¨åœ°æˆªæ–­UTF-8å­—ç¬¦ä¸²ï¼Œé¿å…åœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­
func (s *RagServer) safeUTF8Truncate(str string, maxBytes int) string {
	if len(str) <= maxBytes {
		return str
	}

	// ç¡®ä¿ä¸åœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­
	for i := maxBytes; i >= 0 && i > maxBytes-4; i-- {
		if utf8.ValidString(str[:i]) {
			return str[:i]
		}
	}

	// å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„æˆªæ–­ç‚¹ï¼Œä½¿ç”¨runeçº§åˆ«æˆªæ–­
	runes := []rune(str)
	result := ""
	for _, r := range runes {
		test := result + string(r)
		if len(test) > maxBytes {
			break
		}
		result = test
	}

	return result
}

// sanitizeUTF8 æ¸…ç†å¹¶ç¡®ä¿å­—ç¬¦ä¸²åŒ…å«æœ‰æ•ˆçš„UTF-8å­—ç¬¦
func (s *RagServer) sanitizeUTF8(str string) string {
	if utf8.ValidString(str) {
		return str
	}

	// ç§»é™¤æˆ–æ›¿æ¢æ— æ•ˆçš„UTF-8å­—ç¬¦
	var buf strings.Builder
	buf.Grow(len(str))

	for len(str) > 0 {
		r, size := utf8.DecodeRuneInString(str)
		if r == utf8.RuneError && size == 1 {
			// è·³è¿‡æ— æ•ˆå­—èŠ‚
			str = str[1:]
		} else {
			buf.WriteRune(r)
			str = str[size:]
		}
	}

	return buf.String()
}
