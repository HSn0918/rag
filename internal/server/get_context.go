package server

import (
	"context"
	"fmt"
	"sort"
	"strings"

	"connectrpc.com/connect"
	"github.com/hsn0918/rag/internal/adapters"
	"github.com/hsn0918/rag/internal/clients/openai"
	ragv1 "github.com/hsn0918/rag/internal/gen/rag/v1"
	"github.com/hsn0918/rag/internal/logger"
	"go.uber.org/zap"
)

// GetContext å®ç°æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½
//
// å®Œæ•´çš„RAG(Retrieval-Augmented Generation)æµç¨‹:
// 1. ä½¿ç”¨å¤§æ¨¡å‹æå–ç”¨æˆ·æŸ¥è¯¢ä¸­çš„å…³é”®è¯
// 2. ç”ŸæˆæŸ¥è¯¢å‘é‡è¿›è¡Œè¯­ä¹‰æœç´¢
// 3. å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½é‡æ’åº
// 4. ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”
func (s *RagServer) GetContext(
	ctx context.Context,
	req *connect.Request[ragv1.GetContextRequest],
) (*connect.Response[ragv1.GetContextResponse], error) {
	query := req.Msg.GetQuery()

	if query == "" {
		return nil, connect.NewError(connect.CodeInvalidArgument, fmt.Errorf("query is required"))
	}

	logger.GetLogger().Info("å¼€å§‹å¤„ç†æ™ºèƒ½æ–‡æ¡£æ£€ç´¢è¯·æ±‚",
		zap.String("query", query),
		zap.Int("query_length", len(query)),
	)

	// ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ†è¯å’Œå…³é”®è¯æå–
	keywords, err := s.generateKeywords(ctx, query)
	if err != nil {
		logger.GetLogger().Error("å¤§æ¨¡å‹å…³é”®è¯æå–å¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to generate keywords: %w", err))
	}
	logger.GetLogger().Debug("å¤§æ¨¡å‹å…³é”®è¯æå–å®Œæˆ",
		zap.Strings("keywords", keywords),
	)

	// ç¬¬äºŒæ­¥ï¼šç”Ÿæˆè¯­ä¹‰å‘é‡è¿›è¡Œç›¸ä¼¼æ€§æœç´¢
	// ä¼˜å…ˆä½¿ç”¨æå–çš„å…³é”®è¯ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢
	queryText := strings.Join(keywords, " ")
	if queryText == "" {
		queryText = query
	}
	queryVector, err := s.generateEmbedding(ctx, queryText)
	if err != nil {
		logger.GetLogger().Error("æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to generate query embedding: %w", err))
	}

	// ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œå‘é‡ç›¸ä¼¼æ€§æœç´¢ï¼Œè·å–å€™é€‰æ–‡æ¡£å—
	similarChunks, err := s.searchSimilarChunks(ctx, queryVector, 15) // è·å–æ›´å¤šå€™é€‰ç”¨äºé‡æ’
	if err != nil {
		logger.GetLogger().Error("å‘é‡ç›¸ä¼¼æ€§æœç´¢å¤±è´¥", zap.Error(err))
		return nil, connect.NewError(connect.CodeInternal, fmt.Errorf("failed to search similar chunks: %w", err))
	}

	if len(similarChunks) == 0 {
		logger.GetLogger().Warn("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£", zap.String("query", query))
		return connect.NewResponse(&ragv1.GetContextResponse{
			Context: fmt.Sprintf("æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ '%s' ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚", query),
		}), nil
	}

	// ç¬¬å››æ­¥ï¼šæ™ºèƒ½é‡æ’åº - ç»¼åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…
	rankedChunks := s.rerankChunksWithKeywords(similarChunks, query, keywords)

	// ç¬¬äº”æ­¥ï¼šä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–æ€»ç»“å›ç­”
	contextContent, err := s.generateContextSummary(ctx, rankedChunks, query)
	if err != nil {
		logger.GetLogger().Error("å¤§æ¨¡å‹æ€»ç»“ç”Ÿæˆå¤±è´¥", zap.Error(err))
		// é™çº§åˆ°æ¨¡æ¿å›ç­”
		contextContent = s.buildContextResponse(rankedChunks, query)
	}

	logger.GetLogger().Info("æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å®Œæˆ",
		zap.String("query", query),
		zap.Int("chunks_found", len(similarChunks)),
		zap.Int("chunks_used", len(rankedChunks)),
		zap.Int("response_length", len(contextContent)),
	)

	return connect.NewResponse(&ragv1.GetContextResponse{
		Context: contextContent,
	}), nil
}

// searchSimilarChunks ä½¿ç”¨pgvectoræ‰§è¡Œè¯­ä¹‰å‘é‡æœç´¢
//
// åŸºäºæŸ¥è¯¢å‘é‡åœ¨PostgreSQLæ•°æ®åº“ä¸­æœç´¢ç›¸ä¼¼çš„æ–‡æ¡£å—ï¼Œ
// ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç®—æ³•è®¡ç®—ç›¸å…³æ€§ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
func (s *RagServer) searchSimilarChunks(ctx context.Context, queryVector []float32, limit int) ([]adapters.ChunkSearchResult, error) {
	// ä½¿ç”¨æ•°æ®åº“çš„å‘é‡æœç´¢åŠŸèƒ½
	results, err := s.DB.SearchSimilarChunks(ctx, queryVector, limit, 0.3) // 0.3æ˜¯ç›¸ä¼¼åº¦é˜ˆå€¼
	if err != nil {
		return nil, fmt.Errorf("database search failed: %w", err)
	}

	logger.GetLogger().Debug("Vector search completed",
		zap.Int("results_count", len(results)),
		zap.Int("query_vector_dim", len(queryVector)),
	)

	return results, nil
}

// rerankChunks å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ’åºå’Œè¿‡æ»¤
func (s *RagServer) rerankChunks(chunks []adapters.ChunkSearchResult, query string) []adapters.ChunkSearchResult {
	// åŸºäºå¤šä¸ªå› ç´ è¿›è¡Œé‡æ’åº
	sort.Slice(chunks, func(i, j int) bool {
		// ç»¼åˆè¯„åˆ†ï¼šç›¸ä¼¼åº¦ + å†…å®¹é•¿åº¦ + å…³é”®è¯åŒ¹é…
		scoreI := s.calculateChunkScore(chunks[i], query)
		scoreJ := s.calculateChunkScore(chunks[j], query)
		return scoreI > scoreJ
	})

	// è¿‡æ»¤ä½è´¨é‡ç»“æœï¼Œæœ€å¤šè¿”å›5ä¸ªæœ€ç›¸å…³çš„å—
	maxChunks := 5
	if len(chunks) > maxChunks {
		chunks = chunks[:maxChunks]
	}

	// è¿›ä¸€æ­¥è¿‡æ»¤ï¼šç§»é™¤ç›¸ä¼¼åº¦è¿‡ä½çš„ç»“æœ
	var filteredChunks []adapters.ChunkSearchResult
	for _, chunk := range chunks {
		if chunk.
			Similarity > 0.4 { // ç›¸ä¼¼åº¦é˜ˆå€¼
			filteredChunks = append(filteredChunks, chunk)
		}
	}

	logger.GetLogger().Debug("Chunks reranked and filtered",
		zap.Int("original_count", len(chunks)),
		zap.Int("filtered_count", len(filteredChunks)),
	)

	return filteredChunks
}

// calculateChunkScore è®¡ç®—åˆ†å—çš„ç»¼åˆè¯„åˆ†
func (s *RagServer) calculateChunkScore(chunk adapters.ChunkSearchResult, query string) float64 {
	// åŸºç¡€ç›¸ä¼¼åº¦æƒé‡
	score := float64(chunk.Similarity) * 0.7

	// å†…å®¹é•¿åº¦åŠ åˆ†ï¼ˆé€‚ä¸­é•¿åº¦æ›´å¥½ï¼‰
	contentLength := len(chunk.Content)
	if contentLength > 100 && contentLength < 1000 {
		score += 0.1
	}

	// å…³é”®è¯åŒ¹é…åŠ åˆ†
	queryLower := strings.ToLower(query)
	contentLower := strings.ToLower(chunk.Content)

	// ç®€å•çš„å…³é”®è¯åŒ¹é…è¯„åˆ†
	queryWords := strings.Fields(queryLower)
	matchCount := 0
	for _, word := range queryWords {
		if strings.Contains(contentLower, word) {
			matchCount++
		}
	}

	if len(queryWords) > 0 {
		keywordScore := float64(matchCount) / float64(len(queryWords))
		score += keywordScore * 0.2
	}

	return score
}

// buildContextResponse æ„å»ºç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡å“åº”
func (s *RagServer) buildContextResponse(chunks []adapters.ChunkSearchResult, query string) string {
	if len(chunks) == 0 {
		return fmt.Sprintf("æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ '%s' ç›¸å…³çš„å†…å®¹ã€‚", query)
	}

	var contextBuilder strings.Builder

	// æ·»åŠ æŸ¥è¯¢æ€»ç»“
	contextBuilder.WriteString(fmt.Sprintf("åŸºäºæŸ¥è¯¢ã€Œ%sã€æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³å†…å®¹ï¼š\n\n", query))

	// æ·»åŠ ç›¸å…³å†…å®¹å—
	for i, chunk := range chunks {
		contextBuilder.WriteString(fmt.Sprintf("## ç›¸å…³å†…å®¹ %d (ç›¸ä¼¼åº¦: %.2f)\n", i+1, chunk.Similarity))

		// æ¸…ç†å’Œæ ¼å¼åŒ–å†…å®¹
		cleanContent := s.cleanAndFormatChunkContent(chunk.Content)
		contextBuilder.WriteString(cleanContent)
		contextBuilder.WriteString("\n\n")

		// æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
		if chunk.Metadata != nil {
			if chunkType, ok := chunk.Metadata["chunk_type"].(string); ok && chunkType != "" {
				contextBuilder.WriteString(fmt.Sprintf("*[å†…å®¹ç±»å‹: %s]*\n\n", chunkType))
			}
		}
	}

	// æ·»åŠ ä½¿ç”¨è¯´æ˜
	contextBuilder.WriteString("---\n")
	contextBuilder.WriteString("ğŸ’¡ æç¤ºï¼šä»¥ä¸Šå†…å®¹æŒ‰ç›¸å…³æ€§æ’åºï¼Œæ‚¨å¯ä»¥åŸºäºè¿™äº›ä¿¡æ¯è¿›è¡Œè¿›ä¸€æ­¥çš„è¯¢é—®ã€‚")

	return contextBuilder.String()
}

// cleanAndFormatChunkContent æ¸…ç†å’Œæ ¼å¼åŒ–åˆ†å—å†…å®¹
func (s *RagServer) cleanAndFormatChunkContent(content string) string {
	// åŸºæœ¬æ¸…ç†
	content = strings.TrimSpace(content)

	// ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦
	lines := strings.Split(content, "\n")
	var cleanedLines []string

	lastWasEmpty := false
	for _, line := range lines {
		trimmedLine := strings.TrimSpace(line)

		if trimmedLine == "" {
			if !lastWasEmpty {
				cleanedLines = append(cleanedLines, "")
			}
			lastWasEmpty = true
		} else {
			cleanedLines = append(cleanedLines, trimmedLine)
			lastWasEmpty = false
		}
	}

	// ç¡®ä¿å†…å®¹ä¸ä¼šå¤ªé•¿
	result := strings.Join(cleanedLines, "\n")
	if len(result) > 1000 {
		// æˆªæ–­è¿‡é•¿çš„å†…å®¹ï¼Œä¿ç•™å‰800å­—ç¬¦
		result = result[:800] + "..."
	}

	return result
}

// generateKeywords ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½æå–æŸ¥è¯¢å…³é”®è¯
//
// è°ƒç”¨é…ç½®çš„LLMæœåŠ¡(å¦‚DeepSeek)è¿›è¡Œä¸­æ–‡åˆ†è¯å’Œå…³é”®è¯æå–ï¼Œ
// è‡ªåŠ¨è¿‡æ»¤åœç”¨è¯ï¼Œä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œå®ä½“åè¯ï¼Œ
// å¦‚æœLLMè°ƒç”¨å¤±è´¥ä¼šé™çº§åˆ°æœ¬åœ°ç®€å•åˆ†è¯
func (s *RagServer) generateKeywords(ctx context.Context, query string) ([]string, error) {
	messages := []openai.Message{
		{
			Role: "system",
			Content: `ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡å…³é”®è¯æå–ä¸“å®¶ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ä¸­æå–æœ€é‡è¦çš„å…³é”®è¯ã€‚

è¦æ±‚ï¼š
1. æå–3-8ä¸ªæœ€ç›¸å…³çš„å…³é”®è¯
2. å¿½ç•¥åœè¯ï¼ˆå¦‚ï¼šçš„ã€äº†ã€åœ¨ã€æ˜¯ã€æˆ‘ã€æœ‰ã€å’Œç­‰ï¼‰
3. ä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œå®ä½“åè¯
4. æ¯è¡Œä¸€ä¸ªå…³é”®è¯ï¼Œä¸è¦ç¼–å·
5. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–å†…å®¹

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"è¯·å¸®æˆ‘æ‰¾ä¸€ä¸‹å…³äºæœºå™¨å­¦ä¹ ç®—æ³•çš„èµ„æ–™"
è¾“å‡ºï¼š
æœºå™¨å­¦ä¹ 
ç®—æ³•
èµ„æ–™`,
		},
		{
			Role:    "user",
			Content: query,
		},
	}

	resp, err := s.LLM.CreateChatCompletionWithDefaults(s.Config.Services.LLM.Model, messages)
	if err != nil {
		logger.GetLogger().Error("LLMå…³é”®è¯æå–å¤±è´¥", zap.Error(err))
		// é™çº§ä¸ºç®€å•åˆ†è¯
		return s.fallbackKeywords(query), nil
	}

	if len(resp.Choices) == 0 {
		return s.fallbackKeywords(query), nil
	}

	// è§£æLLMè¿”å›çš„å…³é”®è¯
	content := resp.Choices[0].Message.Content
	lines := strings.Split(strings.TrimSpace(content), "\n")
	var keywords []string

	for _, line := range lines {
		keyword := strings.TrimSpace(line)
		if keyword != "" && len(keyword) > 1 {
			keywords = append(keywords, keyword)
		}
	}

	if len(keywords) == 0 {
		return s.fallbackKeywords(query), nil
	}

	return keywords, nil
}

// fallbackKeywords æœ¬åœ°é™çº§åˆ†è¯å®ç°
//
// å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼Œä½¿ç”¨åŸºäºå­—ç¬¦è§„åˆ™çš„ç®€å•ä¸­æ–‡åˆ†è¯ï¼Œ
// åŒ…å«åŸºç¡€åœç”¨è¯è¿‡æ»¤ï¼Œç¡®ä¿æœåŠ¡çš„å¯ç”¨æ€§
func (s *RagServer) fallbackKeywords(query string) []string {
	// ç®€å•çš„ä¸­æ–‡åˆ†è¯ä½œä¸ºé™çº§æ–¹æ¡ˆ
	stopWords := map[string]bool{
		"çš„": true, "äº†": true, "åœ¨": true, "æ˜¯": true, "æˆ‘": true, "æœ‰": true, "å’Œ": true,
		"å°±": true, "ä¸": true, "äºº": true, "éƒ½": true, "ä¸€": true, "ä¸€ä¸ª": true, "ä¸Š": true,
		"ä¹Ÿ": true, "å¾ˆ": true, "åˆ°": true, "è¯´": true, "è¦": true, "å»": true, "ä½ ": true,
		"ä¼š": true, "ç€": true, "æ²¡æœ‰": true, "çœ‹": true, "å¥½": true, "è‡ªå·±": true, "è¿™": true,
	}

	var keywords []string
	runes := []rune(query)
	var currentWord []rune

	for _, r := range runes {
		if (r >= 0x4e00 && r <= 0x9fff) || (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z') || (r >= '0' && r <= '9') {
			currentWord = append(currentWord, r)
		} else {
			if len(currentWord) > 0 {
				word := string(currentWord)
				if len(word) > 1 && !stopWords[word] {
					keywords = append(keywords, word)
				}
				currentWord = nil
			}
		}
	}

	if len(currentWord) > 0 {
		word := string(currentWord)
		if len(word) > 1 && !stopWords[word] {
			keywords = append(keywords, word)
		}
	}

	return keywords
}

// rerankChunksWithKeywords æ··åˆç®—æ³•æ™ºèƒ½é‡æ’åº
//
// ç»¼åˆå‘é‡ç›¸ä¼¼åº¦(40%)ã€å…³é”®è¯åŒ¹é…(30%)ã€çŸ­è¯­åŒ¹é…(20%)å’Œå†…å®¹è´¨é‡(10%)
// å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åºï¼Œæå‡ç›¸å…³æ€§å’Œå‡†ç¡®æ€§
func (s *RagServer) rerankChunksWithKeywords(chunks []adapters.ChunkSearchResult, query string, keywords []string) []adapters.ChunkSearchResult {
	// ä¸ºæ¯ä¸ªchunkè®¡ç®—ç»¼åˆè¯„åˆ†
	for i := range chunks {
		score := s.calculateAdvancedChunkScore(chunks[i], query, keywords)
		// å°†scoreå­˜å‚¨åœ¨metadataä¸­ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
		if chunks[i].Metadata == nil {
			chunks[i].Metadata = make(map[string]interface{})
		}
		chunks[i].Metadata["advanced_score"] = score
	}

	// æŒ‰ç»¼åˆè¯„åˆ†é‡æ’åº
	sort.Slice(chunks, func(i, j int) bool {
		scoreI, _ := chunks[i].Metadata["advanced_score"].(float64)
		scoreJ, _ := chunks[j].Metadata["advanced_score"].(float64)
		return scoreI > scoreJ
	})

	// è¿‡æ»¤ä½è´¨é‡ç»“æœ
	maxChunks := 5
	if len(chunks) > maxChunks {
		chunks = chunks[:maxChunks]
	}

	var filteredChunks []adapters.ChunkSearchResult
	for _, chunk := range chunks {
		if chunk.Similarity > 0.25 { // é™ä½é˜ˆå€¼ä»¥è·å¾—æ›´å¤šå€™é€‰
			filteredChunks = append(filteredChunks, chunk)
		}
	}

	logger.GetLogger().Debug("Advanced reranking completed",
		zap.Int("original_count", len(chunks)),
		zap.Int("filtered_count", len(filteredChunks)),
		zap.Strings("keywords", keywords),
	)

	return filteredChunks
}

// calculateAdvancedChunkScore å¤šç»´åº¦è¯„åˆ†ç®—æ³•
//
// æƒé‡åˆ†é…: å‘é‡ç›¸ä¼¼åº¦40% + å…³é”®è¯åŒ¹é…30% + çŸ­è¯­åŒ¹é…20% + å†…å®¹è´¨é‡10%
// ç¡®ä¿æ—¢è€ƒè™‘è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œåˆå…¼é¡¾ç²¾ç¡®åŒ¹é…å’Œå†…å®¹å¯è¯»æ€§
func (s *RagServer) calculateAdvancedChunkScore(chunk adapters.ChunkSearchResult, query string, keywords []string) float64 {
	// åŸºç¡€å‘é‡ç›¸ä¼¼åº¦ (40%)
	score := float64(chunk.Similarity) * 0.4

	contentLower := strings.ToLower(chunk.Content)

	// ç²¾ç¡®å…³é”®è¯åŒ¹é… (30%)
	keywordScore := 0.0
	if len(keywords) > 0 {
		matchCount := 0
		for _, keyword := range keywords {
			if strings.Contains(contentLower, strings.ToLower(keyword)) {
				matchCount++
			}
		}
		keywordScore = float64(matchCount) / float64(len(keywords))
	}
	score += keywordScore * 0.3

	// çŸ­è¯­åŒ¹é… (20%)
	queryLower := strings.ToLower(query)
	if strings.Contains(contentLower, queryLower) {
		score += 0.2 // å®Œæ•´æŸ¥è¯¢çŸ­è¯­åŒ¹é…å¥–åŠ±
	}

	// å†…å®¹è´¨é‡è¯„åˆ† (10%)
	contentLength := len(chunk.Content)
	if contentLength > 100 && contentLength < 1500 {
		score += 0.1
	} else if contentLength > 50 {
		score += 0.05
	}

	return score
}

// generateContextSummary ç”Ÿæˆç»“æ„åŒ–ä¸Šä¸‹æ–‡æç¤ºè¯
//
// å°†æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ç‰‡æ®µæ•´ç†æˆç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œ
// ä¾›å…¶ä»–å¤§æ¨¡å‹ä½œä¸ºèƒŒæ™¯çŸ¥è¯†ä½¿ç”¨ï¼Œè€Œä¸æ˜¯ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
func (s *RagServer) generateContextSummary(ctx context.Context, chunks []adapters.ChunkSearchResult, query string) (string, error) {
	if len(chunks) == 0 {
		return "", fmt.Errorf("no chunks to summarize")
	}

	// æ„å»ºç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡æç¤ºè¯
	var contextBuilder strings.Builder

	// æ·»åŠ ä¸Šä¸‹æ–‡è¯´æ˜
	contextBuilder.WriteString("# ç›¸å…³èƒŒæ™¯ä¿¡æ¯\n\n")
	contextBuilder.WriteString(fmt.Sprintf("ç”¨æˆ·æŸ¥è¯¢ï¼š%s\n\n", query))
	contextBuilder.WriteString("ä»¥ä¸‹æ˜¯ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼ŒæŒ‰ç›¸å…³æ€§æ’åºï¼š\n\n")

	// æ·»åŠ æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ
	for i, chunk := range chunks {
		// æ¸…ç†å’Œæ ¼å¼åŒ–å†…å®¹
		cleanContent := s.cleanAndFormatChunkContent(chunk.Content)

		contextBuilder.WriteString(fmt.Sprintf("## å‚è€ƒä¿¡æ¯ %d (ç›¸ä¼¼åº¦: %.3f)\n", i+1, chunk.Similarity))
		contextBuilder.WriteString(cleanContent)
		contextBuilder.WriteString("\n\n")

		// å¦‚æœæœ‰å…ƒæ•°æ®ï¼Œæ·»åŠ æ¥æºä¿¡æ¯
		if chunk.Metadata != nil {
			if chunkType, ok := chunk.Metadata["chunk_type"].(string); ok && chunkType != "" {
				contextBuilder.WriteString(fmt.Sprintf("*[å†…å®¹ç±»å‹: %s]*\n", chunkType))
			}
			if docID, ok := chunk.Metadata["document_id"].(string); ok && docID != "" {
				contextBuilder.WriteString(fmt.Sprintf("*[æ–‡æ¡£ID: %s]*\n", docID))
			}
		}
		contextBuilder.WriteString("\n")
	}

	// æ·»åŠ ä½¿ç”¨æŒ‡å¯¼
	contextBuilder.WriteString("---\n\n")
	contextBuilder.WriteString("**ä½¿ç”¨è¯´æ˜ï¼š**\n")
	contextBuilder.WriteString("- ä»¥ä¸Šä¿¡æ¯æ¥è‡ªå¯ä¿¡çš„çŸ¥è¯†åº“\n")
	contextBuilder.WriteString("- è¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢\n")
	contextBuilder.WriteString("- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜\n")
	contextBuilder.WriteString("- å¯ä»¥é€‚å½“å¼•ç”¨å…·ä½“çš„å‚è€ƒä¿¡æ¯\n")

	contextContent := contextBuilder.String()

	logger.GetLogger().Debug("Context summary generated for external LLM",
		zap.String("query", query),
		zap.Int("chunks_count", len(chunks)),
		zap.Int("context_length", len(contextContent)),
	)

	return contextContent, nil
}

// generateSmartResponse æ¨¡æ¿åŒ–é™çº§å›ç­”ç”Ÿæˆ
//
// å½“LLMæœåŠ¡ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆï¼ŒåŸºäºé¢„è®¾æ¨¡æ¿å’Œè§„åˆ™
// ç”Ÿæˆç»“æ„åŒ–å›ç­”ï¼Œç¡®ä¿ç”¨æˆ·å§‹ç»ˆèƒ½è·å¾—æœ‰ç”¨çš„å“åº”
func (s *RagServer) generateSmartResponse(query string, chunks []adapters.ChunkSearchResult) string {
	var responseBuilder strings.Builder

	// æ·»åŠ é—®é¢˜ç†è§£
	responseBuilder.WriteString(fmt.Sprintf("å…³äºã€Œ%sã€ï¼Œæˆ‘åœ¨ç›¸å…³æ–‡æ¡£ä¸­æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š\n\n", query))

	// åˆ†æå’Œæ€»ç»“å†…å®¹
	for i, chunk := range chunks {
		content := s.cleanAndFormatChunkContent(chunk.Content)
		responseBuilder.WriteString(fmt.Sprintf("**%d. ç›¸å…³ä¿¡æ¯ (ç›¸ä¼¼åº¦: %.2f)**\n", i+1, chunk.Similarity))
		responseBuilder.WriteString(content)
		responseBuilder.WriteString("\n\n")
	}

	// æ·»åŠ æ™ºèƒ½æ€»ç»“
	responseBuilder.WriteString("**æ€»ç»“ï¼š**\n")
	responseBuilder.WriteString("åŸºäºä»¥ä¸Šæ–‡æ¡£å†…å®¹ï¼Œè¿™äº›ä¿¡æ¯æ¶µç›–äº†æ‚¨è¯¢é—®çš„ä¸»è¦æ–¹é¢ã€‚")

	// æ ¹æ®æŸ¥è¯¢ç±»å‹æ·»åŠ ä¸åŒçš„å»ºè®®
	queryLower := strings.ToLower(query)
	if strings.Contains(queryLower, "ç»éªŒ") || strings.Contains(queryLower, "å·¥ä½œ") {
		responseBuilder.WriteString("ä»å·¥ä½œç»éªŒçš„è§’åº¦æ¥çœ‹ï¼Œæ–‡æ¡£ä¸­æåˆ°çš„ç›¸å…³èƒŒæ™¯å’Œå®è·µç»éªŒå¯ä»¥ä¸ºæ‚¨æä¾›å‚è€ƒã€‚")
	} else if strings.Contains(queryLower, "æŠ€æœ¯") || strings.Contains(queryLower, "å¼€å‘") {
		responseBuilder.WriteString("ä»æŠ€æœ¯è§’åº¦åˆ†æï¼Œç›¸å…³çš„æŠ€æœ¯æ ˆå’Œå¼€å‘ç»éªŒåœ¨æ–‡æ¡£ä¸­æœ‰è¯¦ç»†æè¿°ã€‚")
	} else if strings.Contains(queryLower, "é¡¹ç›®") {
		responseBuilder.WriteString("é¡¹ç›®ç›¸å…³çš„ä¿¡æ¯æ˜¾ç¤ºäº†å…·ä½“çš„å®æ–½ç»éªŒå’Œæˆæœã€‚")
	}

	responseBuilder.WriteString("\n\nğŸ’¡ å¦‚éœ€äº†è§£æ›´å…·ä½“çš„ä¿¡æ¯ï¼Œå»ºè®®æ‚¨æŸ¥çœ‹ä¸Šè¿°ç›¸å…³å†…å®¹æˆ–æå‡ºæ›´è¯¦ç»†çš„é—®é¢˜ã€‚")

	return responseBuilder.String()
}
